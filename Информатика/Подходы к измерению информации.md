#МетодыИзмеренияИнформации #ПодходыКИзмерениюИнформации 
#### **Подходы к измерению информации**

#### Кто является отцом информационного века?

Клод Элвуд Шеннон — американский инженер, крипто аналитик и математик. Является основателем теории информации — раздела прикладной математики и радиотехники информатики, относящейся к измерению количества информации, её свойств и устанавливающей предел для системы передачи данных.

##### Три метода измерения информации:

- Объёмный (алфавитный) — основан на подсчёте количества символов и их представлении в коде

- Вероятностный (статистический) — учитывает вероятность событий и ценность менее вероятных сообщений

- Содержательный (сематический) — оценивает информацию по её содержанию

I=log2​N — показывает, сколько бит нужно, чтобы закодировать 1 символ.  
I=K⋅log2​N, где K — количество символов. 


 Информация записывается  
в 0 и 1.  
1 байт = 8 бит.

I — количество бит, N — мощность алфавита.  
N — количество символов.  
log2​ — отражает систему измерения.$$

$$ Пример:  
I=log2​ 33≈5 (округлять до целого).

  I="Привет".  
K=6 (количество символов).  
I=6⋅5=30 бит (слово “Привет”).  
30 бит = 3,75 байт.$$

$$ I=log2​ 26=4,7≈5. 
I="Hello".  
I=5⋅5=25 бит.  
25 бит ≈ 3,125 байт.  

i= log2 28=4,7⋅5

I = brown_fox_jumps_over_the_lazy_dog ** 5 = 33 * 5 = 165 бит = 20 байт

20⋅166 байт=625

Игральная кость: шанс выпадения  

​1/6 =0,167

−log2 0,167 = -2.6 = 2,6 бит

0,167 ⋅ 2,6 ⋅ 6 ≈ 2,605 бит